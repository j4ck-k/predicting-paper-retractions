{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "In this notebook we train various classifiers on our dataset of retracted and non-retracted papers to determine the best model for predicting whether a paper will be retracted. The classifiers we investigate are:\n",
    "1. Logistic Regression\n",
    "2. $k$-Nearest Neighbours\n",
    "3. Random Forests\n",
    "3. Support vector classifiers\n",
    "\n",
    "\n",
    "The KPIs we are interested in are precision, recall, and $F_1$-score. While we are also interested in the accuracy of our classifiers, this measure is less important to us since the retracted and non-retracted classes are massively unbalanced: as we will see, a classifier that simply predicts no retraction for every paper has a 99.7% accuracy!\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "First, we need to prepare our data for the classifiers. To see how our data was collected, take a look at the `example_openAlex_data.ipynb` notebook. Note that we have already split our data into training and testing datasets: the tranining set contains all papers published in 2010-2020 and the testing set contains all paper published in 2021-2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>countries_distinct_count</th>\n",
       "      <th>institutions_distinct_count</th>\n",
       "      <th>referenced_works_count</th>\n",
       "      <th>cited_by_count</th>\n",
       "      <th>authors_distinct_count</th>\n",
       "      <th>any_author_has_retraction</th>\n",
       "      <th>min_retracted_author_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>has_10pct_retracted_author</th>\n",
       "      <th>top_percentile_retracted_author</th>\n",
       "      <th>frac_author_repeat_offenders</th>\n",
       "      <th>any_institution_has_retraction</th>\n",
       "      <th>min_retracted_institution_rank</th>\n",
       "      <th>has_1pct_retracted_institution</th>\n",
       "      <th>has_5pct_retracted_institution</th>\n",
       "      <th>has_10pct_retracted_institution</th>\n",
       "      <th>top_percentile_retracted_institution</th>\n",
       "      <th>is_retracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2919115771</td>\n",
       "      <td>Deep learning</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>55841</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>313.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>94.538771</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2117692326</td>\n",
       "      <td>Hallmarks of Cancer: The Next Generation</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>52921</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>735.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>98.229832</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>61.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>98.941012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W2145339207</td>\n",
       "      <td>Human-level control through deep reinforcement...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>20397</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-inf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W3004280078</td>\n",
       "      <td>A pneumonia outbreak associated with a new cor...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>17439</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>2047.5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>95.064512</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>99.859968</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W3009912996</td>\n",
       "      <td>SARS-CoV-2 Cell Entry Depends on ACE2 and TMPR...</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>16517</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>257.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>95.518992</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  https://openalex.org/W2919115771   \n",
       "1  https://openalex.org/W2117692326   \n",
       "2  https://openalex.org/W2145339207   \n",
       "3  https://openalex.org/W3004280078   \n",
       "4  https://openalex.org/W3009912996   \n",
       "\n",
       "                                               title publication_year  \\\n",
       "0                                      Deep learning             2015   \n",
       "1           Hallmarks of Cancer: The Next Generation             2011   \n",
       "2  Human-level control through deep reinforcement...             2015   \n",
       "3  A pneumonia outbreak associated with a new cor...             2020   \n",
       "4  SARS-CoV-2 Cell Entry Depends on ACE2 and TMPR...             2020   \n",
       "\n",
       "  countries_distinct_count institutions_distinct_count referenced_works_count  \\\n",
       "0                        2                           3                     42   \n",
       "1                        2                           4                    247   \n",
       "2                        1                           2                     19   \n",
       "3                        1                           4                     14   \n",
       "4                        3                          12                     59   \n",
       "\n",
       "  cited_by_count authors_distinct_count  any_author_has_retraction  \\\n",
       "0          55841                      3                      False   \n",
       "1          52921                      2                       True   \n",
       "2          20397                     19                      False   \n",
       "3          17439                     29                       True   \n",
       "4          16517                     13                      False   \n",
       "\n",
       "   min_retracted_author_rank  ...  has_10pct_retracted_author  \\\n",
       "0                       -inf  ...                       False   \n",
       "1                      735.0  ...                        True   \n",
       "2                       -inf  ...                       False   \n",
       "3                     2047.5  ...                        True   \n",
       "4                       -inf  ...                       False   \n",
       "\n",
       "   top_percentile_retracted_author  frac_author_repeat_offenders  \\\n",
       "0                         0.000000                      0.000000   \n",
       "1                        98.229832                      0.500000   \n",
       "2                         0.000000                      0.000000   \n",
       "3                        95.064512                      0.103448   \n",
       "4                         0.000000                      0.000000   \n",
       "\n",
       "   any_institution_has_retraction  min_retracted_institution_rank  \\\n",
       "0                            True                           313.0   \n",
       "1                            True                            61.5   \n",
       "2                           False                            -inf   \n",
       "3                            True                             9.0   \n",
       "4                            True                           257.0   \n",
       "\n",
       "   has_1pct_retracted_institution  has_5pct_retracted_institution  \\\n",
       "0                           False                           False   \n",
       "1                           False                            True   \n",
       "2                           False                           False   \n",
       "3                            True                            True   \n",
       "4                           False                            True   \n",
       "\n",
       "   has_10pct_retracted_institution  top_percentile_retracted_institution  \\\n",
       "0                             True                             94.538771   \n",
       "1                             True                             98.941012   \n",
       "2                            False                              0.000000   \n",
       "3                             True                             99.859968   \n",
       "4                             True                             95.518992   \n",
       "\n",
       "   is_retracted  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('./Data/OpenAlex/openalex-data-2010-2020-train-06.pkl')\n",
    "data.dropna\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are removing features that we do not want to train on, such as `title`, `id`, `publication_year` and `cited_by_count`. While it is true that information such as publication year and the number of citations a work receives can be informative once a paper has been published, these features are very uninformative when considering *new* papers. We are also excluding features involving `min_rank` since some values are `-inf`. Then, we are ensuring that the remaining features are all numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = data.drop(columns=['id', 'title', 'publication_year', 'cited_by_count', 'min_retracted_author_rank', 'min_retracted_institution_rank'])\n",
    "\n",
    "for col in reduced_data.columns:\n",
    "    if reduced_data[col].dtype == bool:\n",
    "        reduced_data[col] = reduced_data[col].astype(int)\n",
    "\n",
    "    elif col in ['publication_year', 'countries_distinct_count', 'institutions_distinct_count', 'referenced_works_count', 'cited_by_count', 'authors_distinct_count']:\n",
    "        reduced_data[col] = reduced_data[col].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply an 80/20 train-test split, making sure to stratify according to the `is_retracted` column of our data frame. This ensures that the distribution of retracted papers is constant in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(reduced_data.copy(), test_size=0.2, stratify=reduced_data['is_retracted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we standardize each of the truly numerical features in our dataset. Note that we are not standardizing features that were previously Boolean and are applying the same transformations to both the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == float:\n",
    "        mean = X_train[col].mean()\n",
    "        std = X_train[col].std()\n",
    "        X_train[col] = (X_train[col] - mean)/std\n",
    "        X_test[col] = (X_test[col] - mean)/std  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Performance Indicators\n",
    "\n",
    "Our KPIs are recall, precision, and $F_1$ score. We use `sklearn`'s confusion matrix to calculate these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return (conf_mat[1][1])/(conf_mat[1][0]+conf_mat[1][1])\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return (conf_mat[1][1])/(conf_mat[0][1]+conf_mat[1][1])\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return (conf_mat[1][1])/(conf_mat[1][1]+0.5*(conf_mat[0][1]+conf_mat[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this notebook, we build a dictionary of KPIs for the models we test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpis = {\n",
    "    'models' : [],\n",
    "    'f1' : [],\n",
    "    'precision' : [],\n",
    "    'recall' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Our baseline model will be a simple logistic regression. Since our dataset is large, we are using the `newton-cg` solver. As this solver only supports $\\ell_2$ regularization, we first use forward stepwise selection to choose an optimal set of features for our regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [[]]\n",
    "\n",
    "features = list(X_train.columns)\n",
    "features.remove('is_retracted')\n",
    "\n",
    "for i in range(len(X_train.columns)-1):\n",
    "    current_features = copy(subsets[i])\n",
    "\n",
    "    best_accuracy  = 0\n",
    "\n",
    "    for feature in features:\n",
    "        model = LogisticRegression(solver='newton-cg')\n",
    "        test_features = current_features.copy()\n",
    "        test_features.append(feature)\n",
    "\n",
    "        X_tt = X_train[test_features]\n",
    "        model.fit(X_tt, X_train['is_retracted'])\n",
    "\n",
    "        accuracy = f1(X_train['is_retracted'], model.predict(X_tt))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            new_feature = feature\n",
    "\n",
    "    current_features.append(new_feature)\n",
    "    if features != []:\n",
    "        features.remove(new_feature)\n",
    "        subsets.append(current_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a model for each set of features determined in our forward stepwise selection and employ 10-fold cross-validation to choose the best model. Note that we are again using *stratified* cross-validation to maintain the distribution of retracted and unretracted papers within each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits = 10, shuffle=True, random_state=123)\n",
    "\n",
    "f1_scores = np.zeros((len(subsets), 10))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train, X_train['is_retracted']):\n",
    "    X_tt = X_train.iloc[train_index]\n",
    "    X_val = X_train.iloc[test_index]\n",
    "\n",
    "    # Baseline model\n",
    "\n",
    "    baseline = np.zeros(len(X_val))\n",
    "\n",
    "    f1_scores[0, i] = f1(X_val.is_retracted, baseline)\n",
    "\n",
    "    for j in range(len(subsets)-1):\n",
    "        subset = subsets[j+1]\n",
    "        model = LogisticRegression(solver='newton-cg')\n",
    "\n",
    "        model.fit(X_tt[subset], X_tt.is_retracted.values)\n",
    "        f1_scores[j+1,i] = f1(X_val.is_retracted.values, model.predict(X_val[subset]))\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 0 F1 Score: 0.0\n",
      "Subset 1 F1 Score: 0.13871575281488485\n",
      "Subset 2 F1 Score: 0.1571756727907499\n",
      "Subset 3 F1 Score: 0.16143383893196123\n",
      "Subset 4 F1 Score: 0.1612869478650249\n",
      "Subset 5 F1 Score: 0.16606550264357964\n",
      "Subset 6 F1 Score: 0.16609934115330635\n",
      "Subset 7 F1 Score: 0.16302470711908365\n",
      "Subset 8 F1 Score: 0.16356783171122782\n",
      "Subset 9 F1 Score: 0.1614814373533083\n",
      "Subset 10 F1 Score: 0.1630528428241459\n",
      "Subset 11 F1 Score: 0.16144338283881146\n",
      "Subset 12 F1 Score: 0.16144338283881146\n",
      "Subset 13 F1 Score: 0.15274650552289837\n",
      "Subset 14 F1 Score: 0.14494006623450667\n",
      "Subset 15 F1 Score: 0.14476462763801543\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(subsets)):\n",
    "    print('Subset', i, 'F1 Score:',np.mean(f1_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s = np.mean(f1_scores, axis=1)\n",
    "best_subset = np.argmax(f1s)\n",
    "\n",
    "best_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Subset 6 has the highest $F_1$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frac_author_repeat_offenders',\n",
       " 'top_percentile_retracted_institution',\n",
       " 'authors_distinct_count',\n",
       " 'referenced_works_count',\n",
       " 'has_1pct_retracted_institution',\n",
       " 'has_10pct_retracted_institution']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets[best_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of features in our best subset, we can see that the most informative single feature is the proportion of authors on a paper that have been previously retracted, followed by a measure of how many retractions any institution related to the paper has received. This makes sense with our intuition for features that may be correlated with a risk of retraction. However, when we look at the distribution of weights in our final model, the most highly weighted feature is the boolean value of whether any associated instituion has had a retraction in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47249703,  1.10095506,  0.11768857,  0.06004498,  0.13091543,\n",
       "        -0.23509377]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train[subsets[best_subset]], X_train['is_retracted'])\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpis['models'].append('Logistic Regression')\n",
    "kpis['f1'].append(f1(X_train['is_retracted'], model.predict(X_train[subsets[best_subset]])))\n",
    "kpis['precision'].append(precision(X_train['is_retracted'], model.predict(X_train[subsets[best_subset]])))\n",
    "kpis['recall'].append(recall(X_train['is_retracted'], model.predict(X_train[subsets[best_subset]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are generating a visualization of the weights for each feature in our model using the `altair` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThemeRegistry.enable('blue')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "def blue():\n",
    "    font = \"Arial\"\n",
    "    \n",
    "    return {\n",
    "        \"config\" : {\n",
    "             \"title\": {'font': font},\n",
    "             \"axis\": {\n",
    "                  \"labelFont\": font,\n",
    "                  \"titleFont\": font\n",
    "             },\n",
    "             'view': {\n",
    "                 'height': 300,\n",
    "                 'width': 600\n",
    "             },\n",
    "          'mark': {\n",
    "                'color': '#9fd1fff2',\n",
    "                'fill': '#9fd1fff2'\n",
    "            }   \n",
    "        }\n",
    "    }\n",
    "\n",
    "alt.themes.register('blue', blue)\n",
    "alt.themes.enable('blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = pd.DataFrame({'features':subsets[best_subset], 'weights':model.coef_[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2522842050a946588410eabf0ed2ed25.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2522842050a946588410eabf0ed2ed25.vega-embed details,\n",
       "  #altair-viz-2522842050a946588410eabf0ed2ed25.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2522842050a946588410eabf0ed2ed25\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2522842050a946588410eabf0ed2ed25\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2522842050a946588410eabf0ed2ed25\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Arial\"}, \"axis\": {\"labelFont\": \"Arial\", \"titleFont\": \"Arial\"}, \"view\": {\"height\": 300, \"width\": 600}, \"mark\": {\"color\": \"#9fd1fff2\", \"fill\": \"#9fd1fff2\"}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"text\": {\"field\": \"weights\", \"format\": \"0.2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"features\", \"sort\": \"-y\", \"title\": \"Feature\", \"type\": \"nominal\"}, \"y\": {\"field\": \"weights\", \"title\": \"Weight\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Feature Weights for Logistic Regression\"}}, {\"mark\": {\"type\": \"text\", \"dy\": -5}, \"encoding\": {\"text\": {\"field\": \"weights\", \"format\": \"0.2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"features\", \"sort\": \"-y\", \"title\": \"Feature\", \"type\": \"nominal\"}, \"y\": {\"field\": \"weights\", \"title\": \"Weight\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Feature Weights for Logistic Regression\"}}], \"data\": {\"name\": \"data-0d4a8f6bb34e28166cc95d3a874aac58\"}, \"height\": 200, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-0d4a8f6bb34e28166cc95d3a874aac58\": [{\"features\": \"frac_author_repeat_offenders\", \"weights\": 0.472497031242419}, {\"features\": \"top_percentile_retracted_institution\", \"weights\": 1.100955062527628}, {\"features\": \"authors_distinct_count\", \"weights\": 0.11768856944046426}, {\"features\": \"referenced_works_count\", \"weights\": 0.06004498186155284}, {\"features\": \"has_1pct_retracted_institution\", \"weights\": 0.13091543198179253}, {\"features\": \"has_10pct_retracted_institution\", \"weights\": -0.23509376507072838}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = alt.Chart(feature_weights, title=alt.Title('Feature Weights for Logistic Regression')).encode(\n",
    "    y=alt.Y('weights').title('Weight'),\n",
    "    x=alt.X('features', axis=alt.Axis(labelAngle=-45)).title('Feature').sort('-y'),\n",
    "    text=alt.Text('weights', format='0.2f')\n",
    ").properties(\n",
    "    width = 600,\n",
    "    height = 200\n",
    ")\n",
    "\n",
    "base.mark_bar() + base.mark_text(dy=-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-Nearest Neighbors\n",
    "\n",
    "We build models that classify our data based on 1-10 neighbours and use stratified 10-fold cross validation to determine an optimal number of neighbours to consider in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "features.remove('is_retracted')\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle=True, random_state=123)\n",
    "\n",
    "f1_scores = np.zeros((10, 10))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train[features], X_train['is_retracted']):\n",
    "    X_tt = X_train.iloc[train_index]\n",
    "    X_val = X_train.iloc[test_index]\n",
    "\n",
    "    for j in range(9):\n",
    "        model = KNeighborsClassifier(n_neighbors=j+1, n_jobs=10)\n",
    "\n",
    "        model.fit(X_tt, X_tt.is_retracted.values)\n",
    "        f1_scores[j,i] = f1(X_val.is_retracted.values, model.predict(X_val))\n",
    "    i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Neighbors F1 Score: 0.895280091156291\n",
      "2 Neighbors F1 Score: 0.8086767338639695\n",
      "3 Neighbors F1 Score: 0.8291684265803049\n",
      "4 Neighbors F1 Score: 0.7496091869234942\n",
      "5 Neighbors F1 Score: 0.774752522886418\n",
      "6 Neighbors F1 Score: 0.7169432792669954\n",
      "7 Neighbors F1 Score: 0.7334112358293066\n",
      "8 Neighbors F1 Score: 0.6799697489271957\n",
      "9 Neighbors F1 Score: 0.6948059094216114\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(i+1, 'Neighbors F1 Score:',np.mean(f1_scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using only the first nearest neighbour gives us the best $F_1$ score, however this model will naturally have very high variance. Thus, we choose to use the top 3 nearest neighbours, since this has a high $F_1$ score with smaller variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3nn = KNeighborsClassifier(n_neighbors=3, n_jobs=10)\n",
    "model_3nn.fit(X_train[features], X_train['is_retracted'])\n",
    "\n",
    "kpis['models'].append('3-Nearest Neighbours')\n",
    "kpis['f1'].append(f1(X_train['is_retracted'], model_3nn.predict(X_train[features])))\n",
    "kpis['precision'].append(precision(X_train['is_retracted'], model_3nn.predict(X_train[features])))\n",
    "kpis['recall'].append(recall(X_train['is_retracted'], model_3nn.predict(X_train[features])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification\n",
    "\n",
    "Here we use a polynomial kernel of degree 3. This was chosen by doing 10-fold cross validation on a much smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = list(X_train.columns)\n",
    "features.remove('is_retracted')\n",
    "\n",
    "model_svc = SVC(kernel='poly', degree = 3, gamma='auto')\n",
    "model_svc.fit(X_train[features], X_train['is_retracted'])\n",
    "\n",
    "kpis['models'].append('SVC')\n",
    "kpis['f1'].append(f1(X_train['is_retracted'], model_svc.predict(X_train[features])))\n",
    "kpis['precision'].append(precision(X_train['is_retracted'], model_svc.predict(X_train[features])))\n",
    "kpis['recall'].append(recall(X_train['is_retracted'], model_svc.predict(X_train[features])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576544315129812"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, max_depth=20)\n",
    "\n",
    "model.fit(X_train[features], X_train['is_retracted'])\n",
    "\n",
    "model.predict(X_test[features])\n",
    "f1(X_train['is_retracted'], model.predict(X_train[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpis['models'].append('Random Forest')\n",
    "kpis['f1'].append(f1(X_train['is_retracted'], model.predict(X_train[features])))\n",
    "kpis['precision'].append(precision(X_train['is_retracted'], model.predict(X_train[features])))\n",
    "kpis['recall'].append(recall(X_train['is_retracted'], model.predict(X_train[features])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpis_df = pd.DataFrame(kpis)\n",
    "kpis_df = kpis_df.melt(id_vars='models', value_vars=['f1','precision', 'recall'], var_name='KPI', value_name='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-adb69ee902f345cf8340f8a7f07726e3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-adb69ee902f345cf8340f8a7f07726e3.vega-embed details,\n",
       "  #altair-viz-adb69ee902f345cf8340f8a7f07726e3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-adb69ee902f345cf8340f8a7f07726e3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-adb69ee902f345cf8340f8a7f07726e3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-adb69ee902f345cf8340f8a7f07726e3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"Arial\"}, \"axis\": {\"labelFont\": \"Arial\", \"titleFont\": \"Arial\"}, \"view\": {\"height\": 300, \"width\": 600}, \"mark\": {\"color\": \"#9fd1fff2\", \"fill\": \"#9fd1fff2\"}}, \"data\": {\"name\": \"data-52a2e42c8016ca84ee224ddf3a4b63f5\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"KPI\", \"type\": \"nominal\"}, \"x\": {\"field\": \"models\", \"title\": \"Model\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Score\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"KPIs for Each Model\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-52a2e42c8016ca84ee224ddf3a4b63f5\": [{\"models\": \"Logistic Regression\", \"KPI\": \"f1\", \"Score\": 0.17016029593094945}, {\"models\": \"3-Nearest Neighbours\", \"KPI\": \"f1\", \"Score\": 0.36014405762304924}, {\"models\": \"Random Forest\", \"KPI\": \"f1\", \"Score\": 0.8576544315129812}, {\"models\": \"Logistic Regression\", \"KPI\": \"precision\", \"Score\": 0.3988439306358382}, {\"models\": \"3-Nearest Neighbours\", \"KPI\": \"precision\", \"Score\": 0.7692307692307693}, {\"models\": \"Random Forest\", \"KPI\": \"precision\", \"Score\": 1.0}, {\"models\": \"Logistic Regression\", \"KPI\": \"recall\", \"Score\": 0.10815047021943573}, {\"models\": \"3-Nearest Neighbours\", \"KPI\": \"recall\", \"Score\": 0.23510971786833856}, {\"models\": \"Random Forest\", \"KPI\": \"recall\", \"Score\": 0.7507836990595611}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot = alt.Chart(kpis_df, title=alt.Title('KPIs for Each Model')).mark_point().encode(\n",
    "    x = alt.X('models', title='Model'),\n",
    "    y = alt.Y('Score'),\n",
    "    color = 'KPI')\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "We can see above that our random forest classifier far outperforms all other models in $F_1$ score, precision and recall. We now test our model on papers published in 2021-2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=500)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, max_depth=20)\n",
    "model.fit(X_train[features], X_train['is_retracted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84673,    13],\n",
       "       [  130,    29]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(X_test['is_retracted'], model.predict(X_test[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.2885572139303483\n",
      "Precision: 0.6904761904761905\n",
      "Recall: 0.18238993710691823\n"
     ]
    }
   ],
   "source": [
    "print('F1:', f1(X_test['is_retracted'], model.predict(X_test[features])))\n",
    "print('Precision:', precision(X_test['is_retracted'], model.predict(X_test[features])))\n",
    "print('Recall:', recall(X_test['is_retracted'], model.predict(X_test[features])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
